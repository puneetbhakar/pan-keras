{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional, Concatenate, Dot, Flatten\n",
    "from keras.layers import Lambda, RepeatVector\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training data\n",
    "data = pd.read_csv(open('../StanceDataset/train.csv', 'rU'), engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating data into different variables\n",
    "X_train = np.asarray(data['Tweet'])\n",
    "X_target = np.asarray(data['Target'])\n",
    "Y_train = np.asarray(data['Stance'])\n",
    "for i, w in enumerate(Y_train):\n",
    "    if w == 'NONE':\n",
    "        Y_train[i] = 0\n",
    "    elif w == 'FAVOR':\n",
    "        Y_train[i] = 1\n",
    "    elif w == 'AGAINST':\n",
    "        Y_train[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get word to index mapping, index to word mapping and word to vector mapping from embedding matrix\n",
    "def read_glove_vecs(file):\n",
    "    word_to_vec_map = {}\n",
    "    word_to_index = {}\n",
    "    index_to_word = {}\n",
    "    i = 0\n",
    "    f = open(file)\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        word_to_index[word] = i\n",
    "        index_to_word[i] = word\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        word_to_vec_map[word] = coefs\n",
    "        i += 1\n",
    "    f.close()\n",
    "    return word_to_index, index_to_word, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('../glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making one-hot vector of targets in training\n",
    "Y_oh_train = to_categorical(Y_train, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting indicies of each word in an example using word to index mapping\n",
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros(shape=(m, max_len))\n",
    "    for i in range(m):\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if word_to_index.get(w) is not None:\n",
    "                X_indices[i, j] = word_to_index.get(w)\n",
    "                j = j+1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making a pretrained embedding matrix from word to vector mapping\n",
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]\n",
    "    emb_matrix = np.zeros(shape=(vocab_len, emb_dim))\n",
    "    for word, i in word_to_index.items():\n",
    "        emb_matrix[i, :] = word_to_vec_map[word]\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable = False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = sentences_to_indices(X_train, word_to_index, 30)\n",
    "targets = sentences_to_indices(X_target, word_to_index, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "def TPAN(input_shape, word_to_vec_map, word_to_index):\n",
    "    \n",
    "    sentence_indices = Input(shape=input_shape, dtype='int32')\n",
    "    target_indices = Input(shape=input_shape, dtype='int32', name='targets')\n",
    "    \n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    target_embeddings = embedding_layer(target_indices)\n",
    "    \n",
    "    target_embeddings = Lambda( lambda x: K.sum(x, axis=1)/30)(target_embeddings)\n",
    "    target_embeddings = RepeatVector(30)(target_embeddings)\n",
    "    target_embeddings = Concatenate(axis=-1)([embeddings, target_embeddings])\n",
    "    \n",
    "    X = Bidirectional(LSTM(25, return_sequences=True))(embeddings)\n",
    "    \n",
    "    Y = Dense(50, activation='softmax')(target_embeddings)\n",
    "    \n",
    "    Z = Dot(axes=1)([Y, X])\n",
    "    Z = Lambda(lambda x: x/30)(Z)\n",
    "    \n",
    "    X = Flatten()(Z)\n",
    "    X = Dense(3)(X)\n",
    "    X = Activation('softmax')(X)\n",
    "    model = Model(inputs=[sentence_indices ,target_indices], outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "targets (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 50)       20000050    input_1[0][0]                    \n",
      "                                                                 targets[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 50)           0           embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 30, 50)       0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 100)      0           embedding_1[0][0]                \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30, 50)       5050        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 50)       15200       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 50, 50)       0           dense_1[0][0]                    \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 50, 50)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2500)         0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            7503        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 3)            0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,027,803\n",
      "Trainable params: 27,753\n",
      "Non-trainable params: 20,000,050\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = TPAN((30,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2914/2914 [==============================] - 5s 2ms/step - loss: 1.0575 - acc: 0.4784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118a6fb50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([tweets, targets], Y_oh_train, epochs = 1, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(open('../StanceDataset/test.csv', 'rU'), engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing of testing data\n",
    "X_test = np.asarray(test_data['Tweet'])\n",
    "X_target_test = np.asarray(test_data['Target'])\n",
    "Y_test = np.asarray(test_data['Stance'])\n",
    "for i, w in enumerate(Y_test):\n",
    "    if w == 'NONE':\n",
    "        Y_test[i] = 0\n",
    "    elif w == 'FAVOR':\n",
    "        Y_test[i] = 1\n",
    "    elif w == 'AGAINST':\n",
    "        Y_test[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 420us/step\n",
      "()\n",
      "('Test accuracy = ', 0.5184049079754601)\n"
     ]
    }
   ],
   "source": [
    "tweets_test = sentences_to_indices(X_test, word_to_index, 30)\n",
    "target_test = sentences_to_indices(X_target_test, word_to_index, 30)\n",
    "Y_oh_test = to_categorical(Y_test, num_classes=3)\n",
    "loss, acc = model.evaluate([tweets_test, target_test], Y_oh_test)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([tweets_test, target_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras Virtual",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
